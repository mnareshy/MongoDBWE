> Mongo offers pluggable storage engines.

> Storage engine is a intermediate layer between the persistent disk and the actual mongodb server itself!
  Mongodb server interacts with the persistent disk through storage engine. The structure of data, indexes and
  Memory optimization decides by the storage engine. Storage engine will have control on memory, it decides
  What to put in disk , what to put in memory and when to put in memory.
  
> MongoDB brings pluggable storage engines , type of storage engine brings different types of performance 
  characteristics to MongoDb.
  
> There are 2 default storage engines comes with the MongoDb bundle 
	1. MMAP(default if you don't specify anything)  2 . WILD TIGER
	
>  Storage engine doesn't impact the the communication between the nodes in the cluster nor the programmers API!

> MMAPv1

>This storage engine uses system mmap internally.

> MongoDB maps the actual file to vm , Os decides what fit in memory. 
	In a given instance if you try to access a page, it may or may not be in memory.
	Os decides which are to be in memory. If you try to read a document if its there in memory
	then you will get it. If its not the OS has to bring it from disk.

> MMAP storage engine offers collection level concurrency , Which is a lock at collection level.
	each collection is a  file in the data / db. If there are multiple write operations on
	same collection, it doesn't work. One write operation at a time on one collection. If multiple
	write operations if different documents it works!

> MongoDB allows in place updates.If it can't it movies to a location as a whole where the document
	fits with the update!. In order to make it more likely that we can update the document in place
	without having to move it, MMAP use power of 2 sizes when we allocate the initial storage for document.

 3 bite document -> gets 4 
 7 bite document -> gets 8 
 19 bite document -> gets 32
 
> with this update in memory can be managed.

> OS decides what is memory and what is in disk. 	

> Wire Tiger

> Not Kind of Document locking, It actually lock free optimistic concurrency model. Storage engine
	Assumes that two writes are not going to be on the same document. If they are on the same document
	Then one of them is unwound and has to try again, which is invisible to the actual application.

> Document level locking vs. collection level locking is the advantage.

> This storage engine offers compression, both of the documents themselves of the data and indexes.

> WT itself manages the memory to read the file from the disk. Memory pages can be vary in size.
	WT only decides which blocks to keep in memory and which blocks to send in disk. WT compress the data
	when it write back to the disk, for some of the data types its huge saving.

> WT append the data directly into the disk , no in-place updates offered. If you update a document which is 
	on memory it actually writes the entire document into disk with updates, and claims the space in memory.
	In cases like a large document update in one area WT write the entire document in to some other place in the disk.

> Data that allows to run without locks at the document level and gives them the document level concurrency.

> mongod -dbpath WT -storageEngine wiredTiger

> WT can not read the files created by MMAP, hence create a separated directory for WT in care you want to use 
	WT storage engine.

> db.movies.stats()

> db.serverStatus().storageEngine

  gives the details of storage!
  
  
> Indexes 

> for instance if there id collection of documents like {"name":"sairam", "EmpInfo":[{},{}...]}
	if there are more number of documents in the collection say few millions , searching for a specific document
	 may be "name" : "xyz" is  a costly operation. documents store in disk could be with any storage engine will 
	 not be in order. hence search is always a costly operation interms of CPU,Memory utilization!
	 
	 Indexes are ordered list of elements those store this physical document location on the disk. When the selected
	 elements are in order its easy for searching something particular.
	 
	 MongoDB uses B-Tree for indexes. Indexes can be on one element on a document or it can be on multiple elements 
	 in the document.
	 
	 if the index is on multiple elements in the  document it works for following combinations.
	 
	 if index is created on  a,b,c
	  index work for searching a  , ab,  abc but not for b , c, bc . its works partially for ac as search works on 
	  a's index and ignores c's.
	  
	 Indexed document insertion is a costly operation. Insertion of non indexed document is faster than indexed one, as
	 it takes time to find the right place in B-Tree for indexing for insertion. This operation seems significant depends 
	 on the size and number of elements indexed. Alternative approach is insert the document wit out index and create the
	 index later on!
	 
	 But the greater advantage is on reads, they will much faster, if the application works on more writes and less reads
	 you need to think if you want to index.
	 
	 creating indexes on many elements is  performance hit as it takes langer time for writes. and it also occupies more
	 disk space for maintaining the indexes.
	
> 	Create indexes -
	i have inserted large number of collection using java program, its in src. 
	
	db.actors.explain().find({"debuyear":{"$eq":2012}})
	
		"winningPlan" : {
			"stage" : "COLLSCAN",
			"filter" : {
				"debuyear" : {
					"$eq" : 2012
				}
			},
			"direction" : "forward"
		},
		
		
	
> db.actors.createIndex({"debutyear":1})
	{
		"createdCollectionAutomatically" : false,
		"numIndexesBefore" : 1,
		"numIndexesAfter" : 2,
		"ok" : 1
	}

	 Which creates index on debutyear
	 
	 now see the difference in  - db.actors.explain().find({"debutyear":{"$eq":2012}})
	 
	 	"winningPlan" : {
			"stage" : "FETCH",
			"inputStage" : {
				"stage" : "IXSCAN",
				"keyPattern" : {
					"debuyear" : 1
				},
				"indexName" : "debuyear_1",
				"isMultiKey" : false,
				"isUnique" : false,
				"isSparse" : false,
				"isPartial" : false,
				"indexVersion" : 1,
				"direction" : "forward",
				"indexBounds" : {
					"debuyear" : [
						"[2012.0, 2012.0]"
					]
				}
			}
	 
	 
	 db.actors.createIndex({"debutyear":1})
	  
	 db.actors.explain(true).find({"debutyear":{"$eq":2012}})
	 // this would give you number of documents examined.

>     db.actors.createIndex({"debutyear":1}) can be in either direction , -1 for in reverse direction.

>  Discovering Index

	db.actors.getIndexes()
	
	[
	{
		"v" : 1,
		"key" : {
			"_id" : 1
		},
		"name" : "_id_",
		"ns" : "test.actors"
	},
	{
		"v" : 1,
		"key" : {
			"debuyear" : 1
		},
		"name" : "debuyear_1",
		"ns" : "test.actors"
	},
	{
		"v" : 1,
		"key" : {
			"debutyear" : 1
		},
		"name" : "debutyear_1",
		"ns" : "test.actors"
	}
	]
	
   There will be default index on _id , that can not be deleted.
   
>  Delete index 
	
	db.actors.dropIndex({"debutyear":1})
	
	{ "nIndexesWas" : 3, "ok" : 1 }
	
	db.actors.getIndexes()
[
	{
		"v" : 1,
		"key" : {
			"_id" : 1
		},
		"name" : "_id_",
		"ns" : "test.actors"
	},
	{
		"v" : 1,
		"key" : {
			"debuyear" : 1
		},
		"name" : "debuyear_1",
		"ns" : "test.actors"
	}
	]

 > Multi key indexes
 
 {
 	"a":[1,2,3,4],
 	"b":3
 }
 
 if you create index on a , where mongodb will create index on 1,2,3 and 4.
 indexes will became multikey indexes when mongodb realizes that the index is on an array of elements.
 index can be created on a and b as a compound index. But if b is also an array then it illegal. 
 
 In the same collection if you try to insert 
 {
 	"a":[1,2,3,4],
 	"b":[3,3]
 }
 
  you will not be allowed. But still the following is allowed
  
   {
 	"a":9,
 	"b":[3,3]
   }
 
 	if you create indexes on arrays 
 
   - db.mk.insertOne({"i":12, "j":17})
 	
   create a component index
 	
   - db.mk.createIndex({"i":1, "j":1})
 
   - db.mk.explain().find({i:1})
    
	"winningPlan" : {
			"stage" : "FETCH",
			"inputStage" : {
				"stage" : "IXSCAN",
				"keyPattern" : {
					"i" : 1,
					"j" : 1
				},
				"indexName" : "i_1_j_1",
				"isMultiKey" : false,

  here multikey is false.
  
  - db.mk.insertOne({"i":12, "j":[17]})
  - db.mk.find()
	{ "_id" : ObjectId("581d92c6b07263e0b7cd0bce"), "i" : 12, "j" : 17 }
	{ "_id" : ObjectId("581d93d3b07263e0b7cd0bcf"), "i" : 12, "j" : [ 17 ] }4
	
  then again 
  
  "winningPlan" : {
			"stage" : "FETCH",
			"inputStage" : {
				"stage" : "IXSCAN",
				"keyPattern" : {
					"i" : 1,
					"j" : 1
				},
				"indexName" : "i_1_j_1",
				"isMultiKey" : false,
  
  -  db.mk.insertOne({"i":12, "j":[17,21,24,27]})
  "winningPlan" : {
			"stage" : "FETCH",
			"inputStage" : {
				"stage" : "IXSCAN",
				"keyPattern" : {
					"i" : 1,
					"j" : 1
				},
				"indexName" : "i_1_j_1",
				"isMultiKey" : true,
  
  The moment mongodb realizes that j is array multikey became true!
																									  
																									  
  - db.mk.insertOne({"i":[12], "j":[17,21,24,27]})
  
  {
	"index" : 0,
	"code" : 10088,
	"errmsg" : "cannot index parallel arrays [j] [i]",
	
	Not allowed, This is weird to me as i is a single element array. When j was created as a single element array
	mongodb did not recognize that its actually multi key index .It only recognized when j became multi element array!
	
  
  - db.mk.insertOne({"i":[12,14,12], "j":[17,21,24,27]})
  
  This cannot be allowed
  
  However the following one is allowed.
  
  - db.mk.insertOne({"i":[12,14,12], "j":12})
  
  On mutlikey indexes, if there a index on 2 keys and key is array . when key 2 is inserted as a single element array MongoDb throws exception.
  
> Dot Notation on mulutikey
	
	when multikey index is create on sub documents in an array, search behaviour is not as we expect!
	
	Sample collection actors
	
	{
	"_id" : ObjectId("581e1cdf35392a0d40a1724d"),
	"name" : "IRHBYUROULYPYEYRWE",
	"debutyear" : 1991,
	"movies" : [
		"TJYQPPHJ",
		"XTTQPHFSTX",
		"IZFCXONCVLZMT",
		"GNPMMNKVJOSSTVXYYO"
	],
	"rating" : [
		{
			"ratingboard" : "national",
			"score" : 77,
			"rank" : 3
		},
		{
			"ratingboard" : "international",
			"score" : 64,
			"rank" : 4
		},
		{
			"ratingboard" : "state",
			"score" : 56,
			"rank" : 3
		},
		{
			"ratingboard" : "imdb",
			"score" : 92,
			"rank" : 8
		}
	]
	
> create a index on rating.score
	
	db.actors.createIndex({"rating.score":1})

> find documents where score is > 90 and rank is lessthan 4
	
	db.actors.find({"rating":{$elemMatch : {"score":{"$gte":90}, "rank":{"$lte":4}}}})

	what it actually does is , it first looks at the indexes to to find out matching documents
	which is all the documents where rating.score > 90 and then gives the result set to run both 
	rank < 4 and score > 90 in one document!
	
	count actually got me 164338
	
	same query wit $and
	
	db.actors.find({$and:[{"rating.score":{"$gte":90}},{"rating.rank":{"$lte":4}}]})
	
	count 333987
	
	surprise! what it has done .... it actually used the indexes which is rating.score and filtered the scored > 90,
	than passed the result set to do the other condition which is rating.rank < 4. which is in contrast with executing
	both the conditions like in $elemMatch case.
	
	
> UNIQUE INDEXES

	unique indexes ensure that the indexed elements are unique. if there are duplicates you cannot create!
	
	- db.employee.createIndex({"empName":1}, {unique:true})
	
	if there are non unique employee name in the collection index will not be created.
	
	you get this error
    {
	"ok" : 0,
	"errmsg" : "E11000 duplicate key error collection: test.employee index: empName_1 dup key: { : \"Emp4\" }",
	"code" : 11000
	}
	
	This is also throws same error when the key is null! so helpful when there is a typo in the key while creating
	indexs.

    
    if there are non unique elements present, index will be created successfully. Now if you try to insert document
    with duplicate empName the following error will be thrown.
    
    ({
	"index" : 0,
	"code" : 11000,
	"errmsg" : "E11000 duplicate key error collection: test.employee index: empName_1 dup key: { : \"Emp4\" }",
	"op" : {
		"_id" : ObjectId("581eac9981f5596dfb7c3112"),
		"empName" : "Emp4"
	}
    })
    
    
> SPARSE INDEX

 db.si.insertMany([
	{i:1,j:2,k:4},
	{i:10,j:20,k:40},
	{i:12,j:22},
	{i:13,j:24}
	])
	
	If you create unique index on the above collection on i or j it works , if you do that on k it wont.
	Reason behind that is document 3,4 does not have key k. k is null in 2 documents hence its not null!
	
 sparse index help us indexing the documents those have k value and leave the documents those doesn't have k.
 
 - db.si.createIndex({k:1},{unique:true, sparce:true})
 
  this doesnt through error  unlike - db.si.createIndex({k:1},{unique:true})
  
 - db.si.explain().find().sort({i:1})  
	 you see   		"inputStage" : {
				"stage" : "IXSCAN",
 
 - db.si.explain().find().sort({k:1})  
	 you see   			"inputStage" : {
					"stage" : "COLLSCAN",
					
  here it cannot use the index scan, and mangodb turned the collection scan as it know its a sparse index
  and there might be documents with out key K.
  
  Hence sparse indexes wont work with sorts!
  
> BACKGROUND INDEX CREATION

	db.actors.createIndex({"debutyear":1},{"background":true})
	
	this will run the index creation in the background.
	if you run index on the foreground  , its  relatively faster but blocks other clients from reads and writes
	on the same data base.
	
	if you run the index creation in the background, its little slower but wont block reads and writes from other clients!
	
	V 2.4 and later, you can create multiple background indexes in parallel even on the same database.
	2.6, creating an index in the background on the primary will cause the indexes to be created in the background on secondaries, as well.
	The secondaries will begin index creation when the primary completes building its index.
	
> EXPLAIN 

 find(), update(), rename(), aggrigate() works with explain() but not insertOne().
 
 .explain() returns explainable object.  Older  versions works with cursors.
 
 new -  db.actors.explain().findOne()
 old - db.actors.findOne().explain() this returns a cursor, this has been updated to new syntax for the following benefit 
 
 db.actors.find().count().explain() doesn't work as count() doesn't return a cursor.
 another example db.actors.remove({"name":"chiranjeevi"}).explain() which does'nt work.
 
 
 but db.actors.explan().find().count() works fine.
 
 var exp = db.actors().explain()
 exp.help() - gives you all operation it can do!
 
 var cursor = db.actors().find()
 cursor.explain() - gives you expain
 now call the .next() get the result -  may be the advantage of using cursor...
 
 
> VERBOSE
 
 	explain has 3 stage of verbose!
 	 
 	 queryPlanner - default
 	 executionStats - this includes queryplanner as well. Give more stats on the number of docs examined ....etc
 	 allPlansExecution -  this includes both queryplanner and executionStats. This in-fact executes all the plans 
 	 in parallel and find the winning plan in contrast with what query optimizer does  periodically!
    
     - db.actors.find().explain()
     - db.actors.find().explain(executionStats)
     - db.actors.find().explain(allPlansExecution)
     
     
> COVERED QUERIES
 
 	
    The query that completely covered by indexes! in case the examined documents are less than or equal to
    the returned documents in look at the executionStats.
     
     
> CHOOSING AN INDEX

	mongodb identifies the opt indexes to use for a query out of available indexes. And it runs all the plans 
	in parallel , which one completes first is going give the results out.
	
	The winning query plan will be stored in the cache for the future use for the queries that shape.
	
	Cache will be evicted from cache in case if the threshold number of writes, or index rebuild or update in index and 
	finally when MongoD restarts.

> INDEX SIZE

	generally the frequently accessed data by clients are called working set, mongoDB keeps the working sets in memory
	because disk io is a costly operation. especially in case of indexes if you keep in disk we loose many advantages 
	of them. Hence its essential to keep the size of index low.
	
	- db.actors.stats()
	 
	 gives you the data about storage and index size.
	 
	 	"nindexes" : 2,
	"totalIndexSize" : 24137728,
	"indexSizes" : {
		"_id_" : 9302016,
		"rating.score_1" : 14835712
	},
	 
	 there is a shortcut method
	 
	 - db.adctors.totalIndexSize()
	 
	If you use WT storage engine , you see its compression(prefix compression) benefits on indexes, hence less 
	memory utilization. However its on the cost of CPU.
	

> INDEX CODINOLITY

	regular -    1 : 1 for every key there is a index point
	sparse - <= documents as it skips the documents that doesn't have the key
	multikey - > documents as it create index for every element in the array.
	
	If the document has 100 tags in it, and if the tags array is indexed with a multikey index, it needs 
	100 index points  to be updated in the index to accommodate the move.
	
>  GEO SEPCIAL INDEXES

	for example you have 4 towns and a you need to find which is close to you.
	MongoDb come with geo special indexes for this kind of problems  and what you need is
	
	an array of 2 elements name something like coordinates, location... your name:)
	
	and 
	
	- ensureIndex({"coordinates":"2d"})
	
	2d is a reserved word,  which tells mongodb that it 2d index. you can have compound index just in case if you have
	type of document as "city" , "town" ..etc
	
	
	- ensureIndex({"coordinates":"2d", "type":1})
	
	now issue the find command
	
	- db.places.find({"coordinates":{"$near":[77,-77]}})
	
	its gives you places close to you in increasing order.
	
	general practice is to use this with limit
	
	- db.places.find({"coordinates":{"$near":[77,-77]}}).limit(2)
	
	try this
	
	- db.places.insertMany([
	{"name":"bangalore", "type":"city" , "coordinates":[71,67]},
	{"name":"madanapalle", "type":"town" , "coordinates":[71,47]},
	{"name":"tirupathi", "type":"city" , "coordinates":[80,33]},
	{"name":"kalahasti", "type":"town" , "coordinates":[47,67]},
	{"name":"mysore", "type":"city" , "coordinates":[78,92]},
	{"name":"mangalore", "type":"city" , "coordinates":[55,67]},
	{"name":"punganur", "type":"town" , "coordinates":[71,77]},
	{"name":"kolar", "type":"town" , "coordinates":[24,67]},
	{"name":"chittoor", "type":"town" , "coordinates":[71,99]},
	{"name":"chintamani", "type":"town" , "coordinates":[63,67]},
	{"name":"hoskote", "type":"town" , "coordinates":[33,67]}
							])
							
	- db.places.ensureIndex({"coordinates":"2d", "type":1})
	
	- db.places.find({"coordinates":{"$near":[77,-77]}}).limit(2)
	
		db.places.find({"coordinates":{"$near":[77,-77]}}).limit(2).pretty()
	{
		"_id" : ObjectId("5820049d2fab980ce1d2681b"),
		"name" : "tirupathi",
		"type" : "city",
		"coordinates" : [
			80,
			33
		]
	}
	{
		"_id" : ObjectId("5820049d2fab980ce1d2681a"),
		"name" : "madanapalle",
		"type" : "town",
		"coordinates" : [
			71,
			47
		]
	}
	
> GEO SEPCIAL SPHERICAL INDEXES

	on earth to position any location we need longitude and latitude.
	
	longitude - longitude refers to the imaginary lines that bisect the globe through the North and South Poles (the ones that run vertically
	latitude -  is a geographic coordinate that specifies the north–south
				position of a point on the Earth's surface. Latitude is an angle (defined below) which ranges from 0° at the 
				Equator to 90° (North or South) at the poles.
				
	
	
	- db.places.insertMany([{"name":"bangalore", "city":"bangalore", "location":{ "type":"Point","coordinates":[76.900919,12.985454]},"type":"city"},
	{"name":"madanapalle", "city":"madanapalle" , "location":{"type":"Point","coordinates":[78.503606,13.560349]},"type":"town"},
	{"name":"tirupathi","city":"tirupathi" , "location":{"type":"Point","coordinates":[79.419179,13.628756]},"type":"city"},
	{"name":"kalahasti", "city":"kalahasti" , "location":{"type":"Point","coordinates":[77.518229,13.044743]},"type":"town"}, 
	{"name":"mysore","city":"mysore" , "location":{"type":"Point","coordinates":[76.639381,12.295810]},"type":"city"},
	{"name":"mangalore","city":"mangalore" , "location":{"type":"Point","coordinates":[74.855957,12.914142]},"type":"city"},
	{"name":"punganur", "city":"punganur","type":"town" , "location":{"type":"Point","coordinates":[78.575014,13.365920]}},
	{"name":"kolar", "city":"kolar", "location":{"type":"Point","coordinates":[78.132561,13.135745]},"type":"town" },
	{"name":"chittoor", "city":"chittoor","type":"town" , "location":{"type":"Point","coordinates":[79.100329,13.217176]},"type":"town"},
	{"name":"chintamani", "city":"chintamani" , "location":{"type":"Point","coordinates":[78.055138,13.401969]},"type":"town"},
	{"name":"mandya", "city":"mandya" , "location":{"type":"Point",	"coordinates":[76.900919,12.522157]},"type":"town"}])
	
	the sub document in the above collection is a specification form geoJson.org 
	
	location":{"type":"point",
		"coordinates":[76.900919,12.522157]
		}
	
    issue the index on the location 
   
	- db.places.ensureIndex({"location":"2dsphere"})						
	
	
	However the below command search the closet location
		
	- db.places.find({location:{$near:{	$geometry:{	type:"Point",coordinates:[76.900919,12.985454]},$maxDistance:2000}}}) 
	
	This is working as not expected! will find out...   TBD
	another sample:
	- db.stores.find({"loc":{$near:{"$geometry":{"type":"Point","coordinates":[-130,39]},$maxDistance: 1000000}}})


> TEXT INDEX

	if there is a text on the key and if you want to search for that you need to pass entire text , otherwise it wont work.
	
	for example if you have a data set like
	
	- db.awards.insertMany([
	{name:"saran", awards:" saran got applause and standing ovation" },
	{name:"akshatha" , awards: "akshatha got  standing ovation "},
	{name:"lakkam" , awards:" lakkam became AM " },
	{name:"rama", awards:" rama got 270 applause points "}
	])
	
	search for the employess those got applause
	
	- db.awards.find({"awards":"applause"}) 
	
	this doesnt work, you need to pass the complete words to match a document. 
	
	create index on the text
	
	- db.awards.ensureIndex({"awards":"text"})
	
	now search for a word
	
	- db.awards.find({"$text":{"$search":"applause"}})
	
	this works for the text search in the document!
	
	- db.awards.find({"$text":{"$search":"lakkam AM applause"}}).pretty()
	
	gives 
	
	{
	"_id" : ObjectId("5820b904e4f9cc0aeae37f42"),
	"name" : "lakkam",
		"awards" : " lakkam became AM "
	}
	{
		"_id" : ObjectId("5820b904e4f9cc0aeae37f40"),
		"name" : "saran",
		"awards" : " saran got applause and standing ovation"
	}
	{
		"_id" : ObjectId("5820b904e4f9cc0aeae37f43"),
		"name" : "rama",
		"awards" : " rama got 270 applause points "
	}
	
	
	Now to find out how good it matches the search string 
	
	
	- db.awards.find({"$text":{"$search":" saran applause"}},{"score":{"$meta":"textScore"}}).sort({"score":{"$meta":"textScore"}}).pretty()
	
	
	we have projected the textScore and then sorted based on the textScore. 
	

> DESIGN AND USING INDEXES

	- selectivity of the index 
	- think on sorts
	
	for selectivity of index , in case query planner scans lot more than the returned documents then think of selecting the appropriate index
	which infact override the query planner index.
	
	- db.actors.find({"debutyear":{"$gte":1997}}).limit(12).sort({"debutyear":-1}).hint({"debutyear":1})
	
	Few thumb rules to follow
	
	1 equity fields before range fields
	2 sort fields before range fields
	3 equity fields before sort fields
	
	 
>  PROFILING AND SLOW QUERIES

	MONGOD presents the slow query log which take more than 100sects on the console.
	
	if you enable profile it wirtes the data on 	system.profiles
	
	there are 3 levels of profiling
	
	0 - no profiling
	1 - log slow queries
	2 - log all queries
	
	
	Enable profiling
	
	- mongod -dbpath /usr/.. --profile 1 --slowms 2
	
	Profiling level set to 1 and this is going to capture any query which take more than 2sec for execution.
	
	on mongo shell you can find the profile log
	
	- db.system.profile.find();
	
	you can use any operator to filter desired results.
	
	- db.getProfilingStatus() - gives the profile status
	- db.getProfilingLevel()
	- db.setProfilingLevel(1,4)  -  this sets the profiling level 1 and slowms to 4
	
	query to look in the system profile collection for all queries that took longer than one second, ordered by timestamp descending.
	
    - db.system.profile.find({"millis":{"$gt":1000}}).sort({"ts":-1}) 
	
> MONGOTOP

	which is written based on unix top command
	
	- mongotop 3 - which give toplevel monitoring data on mongo server on where its actually spending more time for every 3 seconds.
	
	


> MONGOSTAT

	mongostat is built on top of unix iostat command
	
	- mongostat --port
	
	mongostat gives detail information on the ongoing operations , memory ...etc in detail for every 1s sec. It shows the staths for both
	 WT and MMAP storage engines.
	 
	 
	 
> SHARDING

	Sharding is a technique in putting large collection among multiple servers. 
	
	In realword with the large data you dont get desired performance with single server. Hence Shard.
	
	IN sharding there will be multiple mongoservers (mongod's) and each mongo server is a shard. with in shard there could be
	 multiple mongod's which are know as replicas. This is useful when the running server gets into passive state!
	 
	There is something called mangos which works a router between the application and shards. Applictaion always talks to mongos
	 and it mongos job to communicate with appropriate shard.
	 
	mongos identifies the shard in which it anticipates the query data resides in , based on a shard key. Hence for the better 
	 performance client has to send the shard key aswell! if not mongod broadcast the query to all server and it actually loosing the advantage.
	
	
	
	
	
	
	
	
	
	

	
	




